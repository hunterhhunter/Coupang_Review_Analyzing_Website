{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import os\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import rhinoMorph\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm, tqdm_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 1274849110062920894\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 4154458112\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 2607343825132214774\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
       " xla_global_id: 416903419]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예측 과정\n",
    "문장 입력 -> 특수문자 제거 ->\n",
    "형태소분석기 로드 -> 형태소 분석 -> 토크나이저 로드 -> 토크나이징 -> 패딩 -> 모델 로드 -> 모델 예측 -> 긍/부정 라벨링\n",
    "                              -> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 1085\n",
    "\n",
    "class PredictSentence:\n",
    "    \"\"\"한 문장을 예측하는 클래스\"\"\"\n",
    "    def __init__(self, model_path:str, tokenizer_path):\n",
    "        self.model_path = model_path\n",
    "        self.tokenizer_path = tokenizer_path\n",
    "\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"모델, 토크나이저, 형태소 분석기 로드 메서드\"\"\"\n",
    "        self.model = load_model(self.model_path)\n",
    "        print('suceed load_model')\n",
    "        with open(self.tokenizer_path, 'rb') as file:\n",
    "            self.tokenizer = pickle.load(file)\n",
    "        print('suceed load_tokenizer')\n",
    "        self.rn = rhinoMorph.startRhino()\n",
    "\n",
    "\n",
    "    def remove_mark(self, sentence: str):\n",
    "        \"\"\"특수문자 제거 메서드\"\"\"\n",
    "        sentence_no_mark = sentence\n",
    "        marks = [\"?\", \"!\", \"。\", \"‘\", \"’\", \"“\", \"”\", \"`\", \"\\'\",\n",
    "        \"\\\"\", \"(\", \")\", \"{\", \"}\", \"[\", \"]\", \"─\", \"『\", \"』\", \n",
    "        \",\", \"ㆍ\", \"·\", \"ᆞ\", \":\", \";\", \"/\", \"…\", \"_\", \"~\", \n",
    "        \"∼\", \"∽\", \"□\", \"■\", \"▶\", \"◀\", \"◆\", \"▲\", \"◇\", \"◈\", \n",
    "        \"☎\", \"【\", \"】\", \"+\", \"-\", \"=\", \"±\", \"÷\", \"×\", \"*\", \n",
    "        \"^\", \">\", \"<\", \"｜\", \"|\", \"％\", \"%\", \"&\", \"￦\", \"₩\", \n",
    "        \"\\\\\", \"\\t\", \"\\r\\n\", \"\\n\", \"＄\", \"$\", \"¥\", \"￥\", \"£\", \n",
    "        \"￡\", \"°\", \"㎞\", \"㎏\", \"@\", \"©\", \"ⓒ\", \"↑\", \"|\", \"#\", \n",
    "        \"♥\", \"♡\", \"★\", \"☆\", \"♪\", \"♬\", 'ㅋ', 'ㅠ', 'ㅜ']\n",
    "        for mark in marks:\n",
    "            sentence_no_mark = sentence_no_mark.replace(mark, '')\n",
    "        return sentence_no_mark\n",
    "    \n",
    "\n",
    "    def predict(self, sentence: str):\n",
    "        \"한 문장의 긍/부정을 예측하는 메서드\"\n",
    "        self.removed_sentence = self.remove_mark(sentence)\n",
    "        self.tokened_sentence = self.tokenizer.texts_to_sequences([self.removed_sentence])\n",
    "        self.padded_sentence = pad_sequences(self.tokened_sentence, maxlen=maxlen, padding='post')\n",
    "        self.result = self.model.predict(self.padded_sentence)\n",
    "        self.final_result = self.result\n",
    "        \n",
    "        return self.final_result\n",
    "    \n",
    "    def apply_pandas(self, data: pd.Series):\n",
    "        self.applyed_data = data.progress_apply(self.predict)\n",
    "        return self.applyed_data\n",
    "\n",
    "    def test_tokenizer(self, sentence:str):\n",
    "        self.removed_sentence = self.remove_mark(sentence)\n",
    "        print(self.removed_sentence)\n",
    "        self.morphed_sentence = rhinoMorph.onlyMorph_list(self.rn, self.removed_sentence, \n",
    "                                                          pos=['NNG', 'NNP', 'VV', 'VA', 'XR'], eomi=True)\n",
    "        print(f'morphed_sentence: {self.morphed_sentence}')\n",
    "        self.joined_morphed_sentence = ' '.join(self.morphed_sentence)\n",
    "        print(self.joined_morphed_sentence)\n",
    "\n",
    "        self.tokened_sentence = self.tokenizer.texts_to_sequences([self.joined_morphed_sentence])\n",
    "        print(self.tokened_sentence)\n",
    "\n",
    "        self.padded_sentence = pad_sequences(self.tokened_sentence, maxlen=maxlen, padding='post')\n",
    "        print(self.padded_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = PredictSentence(model_path='C:/Users/slugg/Documents/GitHub/three_idiot/model/models/Second_LSTM/10-0.1274.h5', \n",
    "                tokenizer_path='C:/Users/slugg/Documents/GitHub/three_idiot/model/Tokenizer/nomark_tokenizer_28153.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suceed load_model\n",
      "suceed load_tokenizer\n",
      "filepath:  C:\\anaconda3\\Lib\\site-packages\n",
      "classpath:  C:\\anaconda3\\Lib\\site-packages\\rhinoMorph/lib/rhino.jar\n",
      "JVM is already started~\n",
      "RHINO started!\n"
     ]
    }
   ],
   "source": [
    "predictor.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>상품명</th>\n",
       "      <th>상품 코드</th>\n",
       "      <th>구매자 평점</th>\n",
       "      <th>리뷰</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>머렐 MERRELL 여성 기모 스판 본딩 바지, 블랙, 29</td>\n",
       "      <td>7721174639</td>\n",
       "      <td>5</td>\n",
       "      <td>땀복 같다 키 근육 형 핏 예쁘다 요 집 입다 벗다 땀 차다 같다 땀 나다 젖다 안...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>머렐 MERRELL 여성 기모 스판 본딩 바지, 블랙, 29</td>\n",
       "      <td>7721174639</td>\n",
       "      <td>5</td>\n",
       "      <td>평소 사이즈 입다 겨울 껴입다 사이즈 업다 맞다 스판 잇다 활동 하다 모으다 잇다 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>머렐 MERRELL 여성 기모 스판 본딩 바지, 블랙, 29</td>\n",
       "      <td>7721174639</td>\n",
       "      <td>5</td>\n",
       "      <td>신축 성 좋다 핏 예쁘다 평소 사이즈 주문 맞다 핏 작업복 입다 주문 신축 성 좋다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>머렐 MERRELL 여성 기모 스판 본딩 바지, 블랙, 29</td>\n",
       "      <td>7721174639</td>\n",
       "      <td>5</td>\n",
       "      <td>완전 이쁘다 편하다 등산복 구입 방 품다 같다 신축 좋다 속 내복 입다 입다 따뜻하...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>머렐 MERRELL 여성 기모 스판 본딩 바지, 베이지, 28</td>\n",
       "      <td>7721174639</td>\n",
       "      <td>4</td>\n",
       "      <td>이쁘다 평소 입다 허벅지 생각하다 주문 허리 맞다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216382</th>\n",
       "      <td>베이스알파에센셜 여성용 면스판 길이조절 끈나시 3P, 90, 화이트</td>\n",
       "      <td>295583314</td>\n",
       "      <td>5</td>\n",
       "      <td>가격 착하다 끈 길 조절 편하다 기도 하다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216383</th>\n",
       "      <td>베이스알파에센셜 여성용 면스판 길이조절 끈나시 3P, 95, 화이트</td>\n",
       "      <td>295583314</td>\n",
       "      <td>5</td>\n",
       "      <td>좋다 끈 질 되다 면도 좋다 편하다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216384</th>\n",
       "      <td>베이스알파에센셜 여성용 면스판 길이조절 끈나시 3P, 90, 화이트</td>\n",
       "      <td>295583314</td>\n",
       "      <td>5</td>\n",
       "      <td>좋다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216385</th>\n",
       "      <td>베이스알파에센셜 여성용 면스판 길이조절 끈나시 3P, 90, 화이트</td>\n",
       "      <td>295583314</td>\n",
       "      <td>4</td>\n",
       "      <td>입다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216386</th>\n",
       "      <td>베이스알파에센셜 여성용 면스판 길이조절 끈나시 3P, 95, 화이트</td>\n",
       "      <td>295583314</td>\n",
       "      <td>5</td>\n",
       "      <td>길이 조절 도 되다 면도 좋다</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216387 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          상품명       상품 코드  구매자 평점  \\\n",
       "0           머렐 MERRELL 여성 기모 스판 본딩 바지, 블랙, 29  7721174639       5   \n",
       "1           머렐 MERRELL 여성 기모 스판 본딩 바지, 블랙, 29  7721174639       5   \n",
       "2           머렐 MERRELL 여성 기모 스판 본딩 바지, 블랙, 29  7721174639       5   \n",
       "3           머렐 MERRELL 여성 기모 스판 본딩 바지, 블랙, 29  7721174639       5   \n",
       "4          머렐 MERRELL 여성 기모 스판 본딩 바지, 베이지, 28  7721174639       4   \n",
       "...                                       ...         ...     ...   \n",
       "216382  베이스알파에센셜 여성용 면스판 길이조절 끈나시 3P, 90, 화이트   295583314       5   \n",
       "216383  베이스알파에센셜 여성용 면스판 길이조절 끈나시 3P, 95, 화이트   295583314       5   \n",
       "216384  베이스알파에센셜 여성용 면스판 길이조절 끈나시 3P, 90, 화이트   295583314       5   \n",
       "216385  베이스알파에센셜 여성용 면스판 길이조절 끈나시 3P, 90, 화이트   295583314       4   \n",
       "216386  베이스알파에센셜 여성용 면스판 길이조절 끈나시 3P, 95, 화이트   295583314       5   \n",
       "\n",
       "                                                       리뷰  \n",
       "0       땀복 같다 키 근육 형 핏 예쁘다 요 집 입다 벗다 땀 차다 같다 땀 나다 젖다 안...  \n",
       "1       평소 사이즈 입다 겨울 껴입다 사이즈 업다 맞다 스판 잇다 활동 하다 모으다 잇다 ...  \n",
       "2       신축 성 좋다 핏 예쁘다 평소 사이즈 주문 맞다 핏 작업복 입다 주문 신축 성 좋다...  \n",
       "3       완전 이쁘다 편하다 등산복 구입 방 품다 같다 신축 좋다 속 내복 입다 입다 따뜻하...  \n",
       "4                             이쁘다 평소 입다 허벅지 생각하다 주문 허리 맞다  \n",
       "...                                                   ...  \n",
       "216382                            가격 착하다 끈 길 조절 편하다 기도 하다  \n",
       "216383                                좋다 끈 질 되다 면도 좋다 편하다  \n",
       "216384                                                 좋다  \n",
       "216385                                                 입다  \n",
       "216386                                   길이 조절 도 되다 면도 좋다  \n",
       "\n",
       "[216387 rows x 4 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:/Users/slugg/Documents/GitHub/three_idiot/data/전처리_완_데이터/review_여성패션.csv', encoding='cp949', index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216387\n",
      "215499\n"
     ]
    }
   ],
   "source": [
    "print(len(data['리뷰']))\n",
    "print(len(data['리뷰'].dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 125/215499 [00:40<19:30:20,  3.07it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[106], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m droped_data \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m리뷰\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m      2\u001b[0m strd_data \u001b[38;5;241m=\u001b[39m droped_data\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m predict \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrd_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m predict\n",
      "Cell \u001b[1;32mIn[101], line 48\u001b[0m, in \u001b[0;36mPredictSentence.apply_pandas\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_pandas\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: pd\u001b[38;5;241m.\u001b[39mSeries):\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapplyed_data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapplyed_data\n",
      "File \u001b[1;32mc:\\anaconda3\\lib\\site-packages\\tqdm\\std.py:814\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[1;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(df, df_function)(wrapper, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    816\u001b[0m     t\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4357\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4248\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4249\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4252\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4253\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FrameOrSeriesUnion:\n\u001b[0;32m   4254\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4255\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4256\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4355\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4356\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1043\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1040\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m-> 1043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1098\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1092\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1093\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1095\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1096\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1098\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1101\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1105\u001b[0m     \u001b[38;5;66;03m# GH 25959 use pd.array instead of tolist\u001b[39;00m\n\u001b[0;32m   1106\u001b[0m     \u001b[38;5;66;03m# so extension arrays can be used\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(pd_array(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2859\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\anaconda3\\lib\\site-packages\\tqdm\\std.py:809\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    804\u001b[0m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[0;32m    808\u001b[0m     t\u001b[38;5;241m.\u001b[39mupdate(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m<\u001b[39m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 809\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[101], line 42\u001b[0m, in \u001b[0;36mPredictSentence.predict\u001b[1;34m(self, sentence)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokened_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mtexts_to_sequences([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremoved_sentence])\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadded_sentence \u001b[38;5;241m=\u001b[39m pad_sequences(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokened_sentence, maxlen\u001b[38;5;241m=\u001b[39mmaxlen, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadded_sentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_result\n",
      "File \u001b[1;32mc:\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1982\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1980\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   1981\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[1;32m-> 1982\u001b[0m   tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1983\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1984\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "droped_data = data['리뷰'].dropna()\n",
    "strd_data = droped_data.astype(str)\n",
    "predict = predictor.apply_pandas(strd_data)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "23135    1\n",
       "23136    1\n",
       "23137    1\n",
       "23138    1\n",
       "23139    1\n",
       "Name: 리뷰, Length: 23056, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = predict.apply(lambda x: round(x[0][0]))\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\slugg\\AppData\\Local\\Temp\\ipykernel_11160\\3643106245.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['긍/부정 예측'] = dd\n"
     ]
    }
   ],
   "source": [
    "data = data.dropna(subset=['리뷰'])\n",
    "data['긍/부정 예측'] = dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('C:/Users/slugg/Documents/GitHub/three_idiot/data/전처리_예측/review_패션_유아동패션.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "23135    0\n",
       "23136    0\n",
       "23137    0\n",
       "23138    0\n",
       "23139    0\n",
       "Name: 리뷰, Length: 23056, dtype: int32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre = predict.astype(int)\n",
    "pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_data = data.dropna(subset=['리뷰'])\n",
    "drop_data['긍/부정 예측'] = predict\n",
    "drop_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저희 집에 있는 드라이기가 고장이 났는 지 작동이 되다 안되다 오락가락해서 급구매하게되었습니다. 웬만하며 참고 그냥 쓰려고 했는 데 제가 머리 숱이 많은 편이라서요 그리고 집에 있던 드라이기로 머리를 말리면 머리 속이 많이 간지럽더군요 머리카락도 많이 빠졌구요 이유를 몰랐는 데 제게 맞는 제품들을 알아보다가 드라이기 열로 두피가 자극을 받아서일 수도 있을 것 같아 두보 드라이기를 구매했습니다. 일단 제가 생각한 것보다 드라이기 사이즈도 소리도 굉장히 크게 들렸습니다. 제 머리가 긴편은 아니고 어깨정도 오는 데요 세 아이맘이고 8개월 된 아기가 있어 육퇴후 주로 밤에 머리를 감다보니 머리말리는 데 3040분 걸려 덜 말리고 자는 경우도 있었어요 두보 드라이기는 확실히 금방 마르고 선풍기 바람 쐬듯하고 두피도 덜 간지럽네요 머리카락도 덜 빠지네요 가장 높은 온도로 설정 후 쿨버튼 키를 누르고 있으면 시원한 바람이 나오는 데 가장 뜨거운 바람과 차가운 바람을 쿨버튼 하나로 조절이 가능해서 색다른 느낌이 드네요 다만 집에 있는 드라이기는 접이식이라 휴대가 간편하거든요 두보는 접이식이 아니라 아쉽네요 그리고 큰 아이가 평상시에 드라이기로 머리 말릴 때 두피가 뜨겁다고 자주 이야기를 했는 데요 두보 드라이기 소리를 듣고 어떤 행동을 보일 지 궁금하네요 좀 더 써보고 다시 리뷰 올리겠습니다. 제 리뷰가 구매하실 때 도움 되시길 바라며 서로 힘이 되는 좋아요눌러주세요 \n",
      "morphed_sentence: ['집', '드라이기', '고장', '나다', '작동', '되다', '안되다', '오락가락', '급구', '매다', '하다', '웬만', '참다', '쓰리다', '머리', '숱', '많다', '편', '라', '집', '드라이기', '머리', '말리다', '머리', '속', '간지럽다', '머리카락', '빠지다', '이유', '모르다', '맞다', '제품', '알아보다', '드라이기', '열다', '두피', '자극', '받다', '같다', '두보', '드라이기', '구매', '생각하다', '드라이기', '사이즈', '소리', '크다', '들리다', '머리', '길다', '어깨', '정도', '오다', '아이', '마음', '되다', '아기', '있다', '육', '퇴', '후', '밤', '머리', '감다', '머리말', '걸리다', '말리다', '경우', '있다', '두보', '드라이기', '마르다', '선풍기', '쐬다', '두피', '간지럽다', '머리카락', '빠지다', '높다', '온도', '설정', '후', '쿨', '버튼', '키', '누르다', '있다', '시원', '바람', '나오다', '뜨겁다', '바람', '차갑다', '바람', '쿨', '버튼', '하나', '조절', '가능', '색다르다', '느낌', '들다', '집', '드라이기', '접이식', '휴대', '간편', '두보', '접이식', '아쉽다', '크다', '아이', '평상시', '드라이기', '머리', '말리다', '때', '두피', '뜨겁다', '이야기', '하다', '두보', '드라이기', '소리', '듣다', '행동', '보일', '궁금', '써보다', '리뷰', '올리다', '리뷰', '구매', '때', '도움', '되다', '바라다', '힘', '되다', '좋다', '누르다']\n",
      "집 드라이기 고장 나다 작동 되다 안되다 오락가락 급구 매다 하다 웬만 참다 쓰리다 머리 숱 많다 편 라 집 드라이기 머리 말리다 머리 속 간지럽다 머리카락 빠지다 이유 모르다 맞다 제품 알아보다 드라이기 열다 두피 자극 받다 같다 두보 드라이기 구매 생각하다 드라이기 사이즈 소리 크다 들리다 머리 길다 어깨 정도 오다 아이 마음 되다 아기 있다 육 퇴 후 밤 머리 감다 머리말 걸리다 말리다 경우 있다 두보 드라이기 마르다 선풍기 쐬다 두피 간지럽다 머리카락 빠지다 높다 온도 설정 후 쿨 버튼 키 누르다 있다 시원 바람 나오다 뜨겁다 바람 차갑다 바람 쿨 버튼 하나 조절 가능 색다르다 느낌 들다 집 드라이기 접이식 휴대 간편 두보 접이식 아쉽다 크다 아이 평상시 드라이기 머리 말리다 때 두피 뜨겁다 이야기 하다 두보 드라이기 소리 듣다 행동 보일 궁금 써보다 리뷰 올리다 리뷰 구매 때 도움 되다 바라다 힘 되다 좋다 누르다\n",
      "[[96, 38, 97, 74, 261, 3, 95, 6854, 7056, 1202, 1, 1896, 712, 441, 73, 1241, 53, 177, 397, 96, 38, 73, 114, 73, 541, 6529, 573, 279, 278, 88, 113, 11, 257, 38, 366, 830, 4096, 20, 7, 9214, 38, 8, 174, 38, 116, 37, 17, 457, 73, 135, 2050, 26, 23, 156, 24, 3, 1251, 4, 10044, 7864, 78, 558, 73, 250, 770, 209, 114, 258, 4, 9214, 38, 222, 2079, 2986, 830, 6529, 573, 279, 240, 262, 229, 78, 780, 120, 123, 105, 4, 453, 36, 48, 346, 36, 1355, 36, 780, 120, 1236, 145, 66, 5502, 39, 16, 96, 38, 891, 288, 437, 9214, 891, 141, 17, 156, 3003, 38, 73, 114, 15, 830, 346, 614, 1, 9214, 38, 37, 182, 5372, 2229, 1036, 180, 110, 286, 110, 8, 15, 163, 3, 299, 323, 3, 2, 105]]\n",
      "[[96 38 97 ...  0  0  0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.99788016]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(sentence='저희 집에 있는 드라이기가 고장이 났는 지 작동이 되다 안되다 오락가락해서 급구매하게되었습니다. 웬만하며 참고 그냥 쓰려고 했는 데 제가 머리 숱이 많은 편이라서요 그리고 집에 있던 드라이기로 머리를 말리면 머리 속이 많이 간지럽더군요 머리카락도 많이 빠졌구요 이유를 몰랐는 데 제게 맞는 제품들을 알아보다가 드라이기 열로 두피가 자극을 받아서일 수도 있을 것 같아 두보 드라이기를 구매했습니다. 일단 제가 생각한 것보다 드라이기 사이즈도 소리도 굉장히 크게 들렸습니다. 제 머리가 긴편은 아니고 어깨정도 오는 데요 세 아이맘이고 8개월 된 아기가 있어 육퇴후 주로 밤에 머리를 감다보니 머리말리는 데 30~40분 걸려 덜 말리고 자는 경우도 있었어요 두보 드라이기는 확실히 금방 마르고 선풍기 바람 쐬듯하고 두피도 덜 간지럽네요 머리카락도 덜 빠지네요 가장 높은 온도로 설정 후 쿨버튼 키를 누르고 있으면 시원한 바람이 나오는 데 가장 뜨거운 바람과 차가운 바람을 쿨버튼 하나로 조절이 가능해서 색다른 느낌이 드네요 다만 집에 있는 드라이기는 접이식이라 휴대가 간편하거든요 두보는 접이식이 아니라 아쉽네요 그리고 큰 아이가 평상시에 드라이기로 머리 말릴 때 두피가 뜨겁다고 자주 이야기를 했는 데요 두보 드라이기 소리를 듣고 어떤 행동을 보일 지 궁금하네요 좀 더 써보고 다시 리뷰 올리겠습니다. 제 리뷰가 구매하실 때 도움 되시길 바라며 서로 힘이 되는 좋아요~눌러주세요~^^ ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/slugg/Documents/GitHub/three_idiot/model/Tokenizer/nomark_tokenizer_28153.pickle', 'rb') as file:\n",
    "    tokenizer = pickle.load(file)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "reversed_word_index = {}\n",
    "for ke, val in word_index.items():\n",
    "    reversed_word_index[val] = ke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'사'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reversed_word_index[801]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index['로켓']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 빈도분석 (Frequency_Analyze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['만족',\n",
       " '배송',\n",
       " '때',\n",
       " '크다',\n",
       " '빠르다',\n",
       " '디자인',\n",
       " '가성비',\n",
       " '가볍다',\n",
       " '예쁘다',\n",
       " '이쁘다',\n",
       " '바람',\n",
       " '소리',\n",
       " '성능',\n",
       " '저렴',\n",
       " '추천',\n",
       " '화면',\n",
       " '편하다',\n",
       " '최고',\n",
       " '색상',\n",
       " '기능',\n",
       " '깔끔',\n",
       " '작다',\n",
       " '화질',\n",
       " '무겁다',\n",
       " '바꾸다',\n",
       " '사진',\n",
       " '소음',\n",
       " '크기',\n",
       " '무게',\n",
       " '불편',\n",
       " '굿',\n",
       " '미니',\n",
       " '연결',\n",
       " '고장',\n",
       " '배터리',\n",
       " '할인',\n",
       " '이상',\n",
       " '설치',\n",
       " '사이즈',\n",
       " '버튼',\n",
       " '필름',\n",
       " '비싸다',\n",
       " '선물',\n",
       " '튼튼',\n",
       " '포장',\n",
       " '길다',\n",
       " '쉽다',\n",
       " '아쉽다',\n",
       " '단점',\n",
       " '충전',\n",
       " '도착',\n",
       " '아이',\n",
       " '적당',\n",
       " '부드럽다',\n",
       " '보호',\n",
       " '도움',\n",
       " '편리',\n",
       " '색',\n",
       " '블루',\n",
       " '박스',\n",
       " '용량',\n",
       " '친절',\n",
       " '화이트',\n",
       " '정품',\n",
       " '강추',\n",
       " '불량',\n",
       " '세기',\n",
       " '핑크',\n",
       " '손목',\n",
       " '실버',\n",
       " '투명',\n",
       " '고급',\n",
       " '조용',\n",
       " '블랙',\n",
       " '마르다',\n",
       " '무료',\n",
       " '설정',\n",
       " '유튜브',\n",
       " '얇다',\n",
       " '액정',\n",
       " '상태',\n",
       " '품질',\n",
       " '터치',\n",
       " '검색',\n",
       " '높다',\n",
       " '후회',\n",
       " '이벤트',\n",
       " '감도',\n",
       " '전화',\n",
       " '교환',\n",
       " '온도',\n",
       " '무선',\n",
       " '작동',\n",
       " '적다',\n",
       " '적응',\n",
       " '싸다',\n",
       " '기대',\n",
       " '부담',\n",
       " '건조',\n",
       " '먼지',\n",
       " '친구',\n",
       " '고정',\n",
       " '휴대',\n",
       " '전원',\n",
       " '힘들다',\n",
       " '어렵다',\n",
       " '고요',\n",
       " '공간',\n",
       " '반품',\n",
       " '에어',\n",
       " '앱',\n",
       " '음질',\n",
       " '모드',\n",
       " '신경',\n",
       " '색감',\n",
       " '인터넷',\n",
       " '예약',\n",
       " '컬러',\n",
       " '안전',\n",
       " '타자',\n",
       " '사무',\n",
       " '기계식',\n",
       " '설명',\n",
       " '뜨겁다',\n",
       " '깨지다',\n",
       " '아프다',\n",
       " '나쁘다',\n",
       " '기기',\n",
       " '실물',\n",
       " '인식',\n",
       " '서비스',\n",
       " '사운드',\n",
       " '눌리다',\n",
       " '열다',\n",
       " '간단',\n",
       " '구성',\n",
       " '골드',\n",
       " '선명',\n",
       " '색깔',\n",
       " '수납',\n",
       " '깨끗',\n",
       " '가격대',\n",
       " '강력',\n",
       " '단계',\n",
       " '지문',\n",
       " '사전',\n",
       " '패드',\n",
       " '사양',\n",
       " '스타일',\n",
       " '심플',\n",
       " '귀엽다',\n",
       " '무난',\n",
       " '약하다',\n",
       " '쎄다',\n",
       " '퀄리티',\n",
       " '냄새',\n",
       " '늦다',\n",
       " '재질',\n",
       " '간편',\n",
       " '지원',\n",
       " 'USB',\n",
       " '부착',\n",
       " '요금',\n",
       " '넓다',\n",
       " '시원',\n",
       " '무게감',\n",
       " '부족',\n",
       " '헤어',\n",
       " '보관',\n",
       " '빨래',\n",
       " '날',\n",
       " '그립',\n",
       " '훌륭',\n",
       " '설명서',\n",
       " '느리다',\n",
       " '마감',\n",
       " '완벽',\n",
       " '발열',\n",
       " '자판',\n",
       " '방법',\n",
       " '커버',\n",
       " '세탁기',\n",
       " '디스플레이',\n",
       " '짧다',\n",
       " '가죽',\n",
       " '활용',\n",
       " '여행',\n",
       " '거치',\n",
       " '넉넉',\n",
       " '통화',\n",
       " '시작',\n",
       " '흰색',\n",
       " '내구',\n",
       " '대박',\n",
       " '귀찮다',\n",
       " '입력',\n",
       " '슬림',\n",
       " '충분',\n",
       " '익숙',\n",
       " '캡',\n",
       " '외관',\n",
       " '노즐',\n",
       " '케이블',\n",
       " '실리콘',\n",
       " '시끄럽다',\n",
       " '촬영',\n",
       " '맛',\n",
       " '개봉',\n",
       " '타입',\n",
       " '램',\n",
       " '행복',\n",
       " '각도',\n",
       " '냉장',\n",
       " '금액',\n",
       " '빛',\n",
       " '싫다',\n",
       " '두껍다',\n",
       " '패널',\n",
       " '스펙',\n",
       " '방지',\n",
       " '파손',\n",
       " '타이핑',\n",
       " '변색',\n",
       " '태블릿',\n",
       " '택배',\n",
       " '영롱',\n",
       " '뽁뽁',\n",
       " '불안',\n",
       " '착용',\n",
       " '낮다',\n",
       " '밝다',\n",
       " '호환',\n",
       " '볼륨',\n",
       " '만족도',\n",
       " '건전지',\n",
       " '모터',\n",
       " '손가락',\n",
       " '아깝다',\n",
       " '떨다',\n",
       " '결제',\n",
       " '냉동실',\n",
       " '오래가다',\n",
       " '유선',\n",
       " '사고',\n",
       " '견고',\n",
       " '조립',\n",
       " '고가',\n",
       " '위치',\n",
       " '리스',\n",
       " '숫자',\n",
       " '묵직',\n",
       " '손잡이',\n",
       " '내부',\n",
       " '손상',\n",
       " '렌즈',\n",
       " '새롭다',\n",
       " '망가지다',\n",
       " '프로그램',\n",
       " '모서리',\n",
       " '문자',\n",
       " '어둡다',\n",
       " '튀어나오다',\n",
       " '길이',\n",
       " '세련',\n",
       " '안심',\n",
       " '최신',\n",
       " '환불',\n",
       " '장착',\n",
       " '모양',\n",
       " '레드',\n",
       " '두께',\n",
       " '청소',\n",
       " '닳다',\n",
       " '실망',\n",
       " '통',\n",
       " '흔들리다',\n",
       " '불빛',\n",
       " '뒷면',\n",
       " '조작',\n",
       " '세탁',\n",
       " '뛰어나다',\n",
       " '연동',\n",
       " '방수',\n",
       " '양',\n",
       " '모발',\n",
       " '두피',\n",
       " '움직이다',\n",
       " '효율',\n",
       " '전문가',\n",
       " '상자',\n",
       " '검정',\n",
       " '오피스',\n",
       " '강화유리',\n",
       " '충격',\n",
       " '기포',\n",
       " '용이',\n",
       " '엄청나다',\n",
       " '접히다',\n",
       " '단자',\n",
       " '채널',\n",
       " '꺼지다',\n",
       " '업데이트',\n",
       " '무광',\n",
       " '스위치',\n",
       " '선호',\n",
       " '접이식',\n",
       " '당황',\n",
       " '부팅',\n",
       " '포트',\n",
       " '중국',\n",
       " '그레이',\n",
       " '고객센터',\n",
       " '뻑뻑',\n",
       " '인증',\n",
       " '머릿결']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_file(path: str, encoding: str='cp949'):\n",
    "    with open(path, 'r', encoding=encoding) as file:\n",
    "        keyword = [line for line in file.readlines()]\n",
    "    return keyword\n",
    "\n",
    "keywords = read_file(path='C:/Users/slugg/Documents/GitHub/three_idiot/data/언어사전/빈도분석단어모음_928to315.txt', encoding='euc-kr')\n",
    "for index, keyword in enumerate(keywords):\n",
    "    if '\\n' in keyword:\n",
    "        keyword = keyword.replace('\\n', '')\n",
    "        keywords[index] = keyword\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Union\n",
    "class FrequencyAnalyzer:\n",
    "    \"\"\"빈도분석 클래스\"\"\"\n",
    "    def __init__(self, key_path: str):\n",
    "        self.keyword_path = key_path\n",
    "        self.product_keyword_counts_info = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    def read_file(self, encoding: str='utf-8'):\n",
    "        with open(self.keyword_path, 'r', encoding=encoding) as file:\n",
    "            keywords = [line for line in file.readlines()]\n",
    "\n",
    "        for index, keyword in enumerate(keywords):\n",
    "            if '\\n' in keyword:\n",
    "                keyword = keyword.replace('\\n', '')\n",
    "                keywords[index] = keyword\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        return keywords\n",
    "    \n",
    "    def morph(self, sentence):\n",
    "        morphed_sentence = rhinoMorph.onlyMorph_list(self.rn, sentence, \n",
    "                                                    pos=['NNG', 'NNP', 'VV', 'VA', 'XR'], eomi=True)\n",
    "        joined_sentence = ' '.join(morphed_sentence)\n",
    "        return joined_sentence\n",
    "\n",
    "    def analyze_one_reviews_with_dataframe(self, data: pd.DataFrame) -> Dict[str, Dict[str, Union[str, int]]]:\n",
    "        \"\"\"한 제품의 리뷰를 받아 분석하는 메서드\"\"\"\n",
    "        self.data = data\n",
    "        self.count_stars = [data['사용자 별점'].value_counts()]\n",
    "        self.prod_num = data['상품 코드'].iloc[0]\n",
    "        drop_data = data.dropna(subset=['리뷰'])\n",
    "        self.strd_data = drop_data['리뷰'].astype(str)\n",
    "        \n",
    "        for product, group in strd_data:\n",
    "            total_reviews = len(group)\n",
    "            positive_group = group[group['평점'] == 1]\n",
    "            negetive_group = group[group['평점'] == 0]\n",
    "            total_positive_reviews = len(positive_group)\n",
    "            total_negetive_reviews = len(negetive_group)\n",
    "\n",
    "            self.pos_keyword_counts = defaultdict(int)\n",
    "            self.neg_keyword_counts = defaultdict(int)\n",
    "\n",
    "            for review in positive_group.iloc[:, 1]:\n",
    "                for keyword in keywords:\n",
    "                    if keyword in review:\n",
    "                        self.pos_keyword_counts[keyword] += 1\n",
    "            \n",
    "            for review in negetive_group.iloc[:, 1]:\n",
    "                for keyword in keywords:\n",
    "                    if keyword in review:\n",
    "                        self.neg_keyword_counts[keyword] += 1\n",
    "\n",
    "            # 상위 5개 긍정 키워드 선택\n",
    "            top_5_pos_keywords = sorted(self.pos_keyword_counts.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "            # 상위 5개 부정 키워드 선택\n",
    "            top_5_neg_keywords = sorted(self.neg_keyword_counts.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "            self.product_keyword_counts_info[product]['total_reviews'] = total_reviews\n",
    "            self.product_keyword_counts_info[product]['total_positive_reviews'] = total_positive_reviews\n",
    "            self.product_keyword_counts_info[product]['total_negative_reviews'] = total_negetive_reviews\n",
    "            self.product_keyword_counts_info[product]['top_5_pos_keywords'] = top_5_pos_keywords\n",
    "            self.product_keyword_counts_info[product]['top_5_neg_keywords'] = top_5_neg_keywords\n",
    "            \n",
    "        return self.product_keyword_counts_info\n",
    "    \n",
    "    def analyze_all_reviews_with_dataframe(self, data: pd.DataFrame) -> Dict[str, Dict[str, Union[str, int]]]:\n",
    "        \"\"\"모든 제품의 리뷰를 받아 분석하는 메서드\"\"\"\n",
    "        self.data = data\n",
    "        drop_data = data.dropna(subset=['리뷰']) # 리뷰 없는 행 제거\n",
    "        drop_data['상품 코드'] = drop_data['상품 코드'].astype(str)\n",
    "\n",
    "        for product, group in drop_data.groupby('상품 코드'): # 상품명으로 묶어 같은 상품 리뷰 처리\n",
    "            count_stars = group['구매자 평점'].value_counts().sort_index() # 별점 개수 카운팅\n",
    "            index = count_stars.index\n",
    "            ret_dict = {ind: cnt_star for ind, cnt_star in zip(index, count_stars.values.tolist())} # 별점 개수 딕셔너리로 저장\n",
    "            # prod_num = group['상품 코드'].iloc[0] # 상품 코드 저장\n",
    "            total_reviews = len(group)\n",
    "            positive_group = group[group['긍/부정 예측'] == 1]\n",
    "            negetive_group = group[group['긍/부정 예측'] == 0]\n",
    "            total_positive_reviews = len(positive_group)\n",
    "            total_negetive_reviews = len(negetive_group)\n",
    "\n",
    "            pos_keyword_counts = defaultdict(int)\n",
    "            neg_keyword_counts = defaultdict(int)\n",
    "\n",
    "            for review in positive_group['리뷰']:\n",
    "                for keyword in keywords:\n",
    "                    if keyword in review:\n",
    "                        pos_keyword_counts[keyword] += 1\n",
    "            \n",
    "            for review in negetive_group['리뷰']:\n",
    "                for keyword in keywords:\n",
    "                    if keyword in review:\n",
    "                        neg_keyword_counts[keyword] += 1\n",
    "\n",
    "            # 상위 5개 긍정 키워드 선택\n",
    "            top_5_pos_keywords = sorted(pos_keyword_counts.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "            # 상위 5개 부정 키워드 선택\n",
    "            top_5_neg_keywords = sorted(neg_keyword_counts.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "            self.product_keyword_counts_info[product]['total_reviews'] = total_reviews\n",
    "            self.product_keyword_counts_info[product]['total_positive_reviews'] = total_positive_reviews\n",
    "            self.product_keyword_counts_info[product]['total_negative_reviews'] = total_negetive_reviews\n",
    "            self.product_keyword_counts_info[product]['top_5_pos_keywords'] = top_5_pos_keywords\n",
    "            self.product_keyword_counts_info[product]['top_5_neg_keywords'] = top_5_neg_keywords\n",
    "            self.product_keyword_counts_info[product]['star_count'] = ret_dict\n",
    "            # self.product_keyword_counts_info[product]['prod_num'] = prod_num\n",
    "            \n",
    "        return self.product_keyword_counts_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "al = FrequencyAnalyzer(key_path='C:/Users/slugg/Documents/GitHub/three_idiot/data/언어사전/패션.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['사이즈',\n",
       " '크다',\n",
       " '아이',\n",
       " '이쁘다',\n",
       " '예쁘다',\n",
       " '귀엽다',\n",
       " '좋아하다',\n",
       " '편하다',\n",
       " '가격',\n",
       " '세탁',\n",
       " '괜찮다',\n",
       " '재질',\n",
       " '디자인',\n",
       " '작다',\n",
       " '만족',\n",
       " '얇다',\n",
       " '넉넉',\n",
       " '색상',\n",
       " '길다',\n",
       " '배송',\n",
       " '길이',\n",
       " '핏',\n",
       " '부드럽다',\n",
       " '따뜻',\n",
       " '색',\n",
       " '짧다',\n",
       " '겨울',\n",
       " '저렴',\n",
       " '허리',\n",
       " '여아',\n",
       " '아들',\n",
       " '원단',\n",
       " '춥다',\n",
       " '불편',\n",
       " '여유',\n",
       " '보풀',\n",
       " '두께',\n",
       " '추천',\n",
       " '도톰',\n",
       " '가성비',\n",
       " '소재',\n",
       " '한치수',\n",
       " '마른',\n",
       " '신축',\n",
       " '두껍다',\n",
       " '늘어나다',\n",
       " '적당',\n",
       " '줄어들다',\n",
       " '아쉽다',\n",
       " '색감',\n",
       " '활동',\n",
       " '색깔',\n",
       " '건조',\n",
       " '기장',\n",
       " '발목',\n",
       " '화면',\n",
       " '깔끔',\n",
       " '선물',\n",
       " '반품',\n",
       " '줄다',\n",
       " '소매',\n",
       " '따뜻하다',\n",
       " '고무줄',\n",
       " '교환',\n",
       " '어울리다',\n",
       " '컬러',\n",
       " '품질',\n",
       " '울다',\n",
       " '편안',\n",
       " '가볍다',\n",
       " '고민',\n",
       " '덥다',\n",
       " '싸이즈',\n",
       " '쫀쫀',\n",
       " '짱짱',\n",
       " '스판',\n",
       " '색도',\n",
       " '스타일',\n",
       " '밴딩',\n",
       " '엉덩이',\n",
       " '시원',\n",
       " '캐릭터',\n",
       " '촉감',\n",
       " '마감',\n",
       " '두툼',\n",
       " '먼지',\n",
       " '프린팅',\n",
       " '무난',\n",
       " '작아지다',\n",
       " '냄새',\n",
       " '싸다',\n",
       " '구멍',\n",
       " '착용',\n",
       " '실밥',\n",
       " '실내',\n",
       " '퀄리티',\n",
       " '밴드',\n",
       " '상태',\n",
       " '브랜드',\n",
       " '날씬',\n",
       " '치수',\n",
       " '아이보리',\n",
       " '착용감',\n",
       " '넓다',\n",
       " '박음질',\n",
       " '체형',\n",
       " '강추',\n",
       " '변형',\n",
       " '바느질',\n",
       " '안감',\n",
       " '아깝다',\n",
       " '화사',\n",
       " '크기',\n",
       " '흘러내리다',\n",
       " '조이다',\n",
       " '체격',\n",
       " '코디',\n",
       " '뻣뻣',\n",
       " '옷감',\n",
       " '답답',\n",
       " '순면',\n",
       " '봄',\n",
       " '가을',\n",
       " '한겨울',\n",
       " '프린트',\n",
       " '버리다',\n",
       " '무릎',\n",
       " '허벅지',\n",
       " '타이트하다',\n",
       " '무늬',\n",
       " '다리다',\n",
       " '늘어지다',\n",
       " '형광',\n",
       " '덮다',\n",
       " '애매',\n",
       " '키우다',\n",
       " '맞추다',\n",
       " '슬림',\n",
       " '헐렁',\n",
       " '고무',\n",
       " '후회',\n",
       " '폴라',\n",
       " '보온',\n",
       " '주머니',\n",
       " '어깨',\n",
       " '보들보들',\n",
       " '패턴',\n",
       " '고급',\n",
       " '귀여움',\n",
       " '보드랍다',\n",
       " '폴리',\n",
       " '데일리',\n",
       " '커플',\n",
       " '깜찍',\n",
       " '튼튼',\n",
       " '손빨래',\n",
       " '실물',\n",
       " '자국',\n",
       " '득템',\n",
       " '빳빳',\n",
       " '지저분',\n",
       " '환불',\n",
       " '자수',\n",
       " '꼼꼼',\n",
       " '수선',\n",
       " '불량',\n",
       " '지퍼',\n",
       " '무겁다',\n",
       " '둘레',\n",
       " '종아리',\n",
       " '검수',\n",
       " '달라붙다',\n",
       " '접히다',\n",
       " '끌리다',\n",
       " '겉감',\n",
       " '손세탁',\n",
       " '싸구려']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "al.read_file(encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>상품명</th>\n",
       "      <th>상품 코드</th>\n",
       "      <th>구매자 평점</th>\n",
       "      <th>리뷰</th>\n",
       "      <th>긍/부정 예측</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>월튼키즈 남아용 체커보드 플리스 상하의 세트, 블랙, 140</td>\n",
       "      <td>7636639833</td>\n",
       "      <td>5</td>\n",
       "      <td>화면 동일 험하다 다니다 남자아이 한철 입 생각 가격 저렴 구매 만족 세탁 후 어떻...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>월튼키즈 남아용 체커보드 플리스 상하의 세트, 블랙, 130</td>\n",
       "      <td>7636639833</td>\n",
       "      <td>5</td>\n",
       "      <td>예쁘다 두다 하다 가격 대비 남다 마른 체형 여유 잇지 사이즈 입다 내복 입다 따뜻...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>월튼키즈 남아용 체커보드 플리스 상하의 세트, 블랙, 130</td>\n",
       "      <td>7636639833</td>\n",
       "      <td>5</td>\n",
       "      <td>살다 맞다 넘다 가 따다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>월튼키즈 남아용 체커보드 플리스 상하의 세트, 블랙, 120</td>\n",
       "      <td>7636639833</td>\n",
       "      <td>1</td>\n",
       "      <td>빨다 하얗다 부분 검정 물 이염 방지 시트 넣다 빨다 입다 버리다 되다 물들다 디자...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>마리앤모리 아동용 체크 후리스 기모 상하복 세트, 120, 베이지</td>\n",
       "      <td>7714261280</td>\n",
       "      <td>5</td>\n",
       "      <td>키 몸무게 소재 가 따뜻 색상 이쁘다 서얼 굴 살다 요바 짧다 느낌 있다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23135</th>\n",
       "      <td>메이키즈 아동용 삐약이 7부 쟈가드 실내복, 90호, 옐로우</td>\n",
       "      <td>185480437</td>\n",
       "      <td>5</td>\n",
       "      <td>받다 감사</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23136</th>\n",
       "      <td>메이키즈 아동용 삐약이 7부 쟈가드 실내복, 110호, 옐로우</td>\n",
       "      <td>185480437</td>\n",
       "      <td>5</td>\n",
       "      <td>배송 빠르다 옷 넘넘 귀엽다 좋다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23137</th>\n",
       "      <td>메이키즈 아동용 삐약이 7부 쟈가드 실내복, 110호, 옐로우</td>\n",
       "      <td>185480437</td>\n",
       "      <td>4</td>\n",
       "      <td>귀엽다 사이즈 크다 빠르다 배송 굳</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23138</th>\n",
       "      <td>메이키즈 아동용 삐약이 7부 쟈가드 실내복, 140호, 옐로우</td>\n",
       "      <td>185480437</td>\n",
       "      <td>5</td>\n",
       "      <td>주문 여유 있다 좋다 화사 예 ㅃ 배송 하루 빠르다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23139</th>\n",
       "      <td>메이키즈 아동용 삐약이 7부 쟈가드 실내복, 140호, 옐로우</td>\n",
       "      <td>185480437</td>\n",
       "      <td>5</td>\n",
       "      <td>시원 편하다 좋다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23056 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        상품명       상품 코드  구매자 평점  \\\n",
       "0         월튼키즈 남아용 체커보드 플리스 상하의 세트, 블랙, 140  7636639833       5   \n",
       "1         월튼키즈 남아용 체커보드 플리스 상하의 세트, 블랙, 130  7636639833       5   \n",
       "2         월튼키즈 남아용 체커보드 플리스 상하의 세트, 블랙, 130  7636639833       5   \n",
       "3         월튼키즈 남아용 체커보드 플리스 상하의 세트, 블랙, 120  7636639833       1   \n",
       "4      마리앤모리 아동용 체크 후리스 기모 상하복 세트, 120, 베이지  7714261280       5   \n",
       "...                                     ...         ...     ...   \n",
       "23135     메이키즈 아동용 삐약이 7부 쟈가드 실내복, 90호, 옐로우   185480437       5   \n",
       "23136    메이키즈 아동용 삐약이 7부 쟈가드 실내복, 110호, 옐로우   185480437       5   \n",
       "23137    메이키즈 아동용 삐약이 7부 쟈가드 실내복, 110호, 옐로우   185480437       4   \n",
       "23138    메이키즈 아동용 삐약이 7부 쟈가드 실내복, 140호, 옐로우   185480437       5   \n",
       "23139    메이키즈 아동용 삐약이 7부 쟈가드 실내복, 140호, 옐로우   185480437       5   \n",
       "\n",
       "                                                      리뷰  긍/부정 예측  \n",
       "0      화면 동일 험하다 다니다 남자아이 한철 입 생각 가격 저렴 구매 만족 세탁 후 어떻...        1  \n",
       "1      예쁘다 두다 하다 가격 대비 남다 마른 체형 여유 잇지 사이즈 입다 내복 입다 따뜻...        1  \n",
       "2                                          살다 맞다 넘다 가 따다        0  \n",
       "3      빨다 하얗다 부분 검정 물 이염 방지 시트 넣다 빨다 입다 버리다 되다 물들다 디자...        0  \n",
       "4               키 몸무게 소재 가 따뜻 색상 이쁘다 서얼 굴 살다 요바 짧다 느낌 있다        0  \n",
       "...                                                  ...      ...  \n",
       "23135                                              받다 감사        1  \n",
       "23136                                 배송 빠르다 옷 넘넘 귀엽다 좋다        1  \n",
       "23137                                귀엽다 사이즈 크다 빠르다 배송 굳        1  \n",
       "23138                       주문 여유 있다 좋다 화사 예 ㅃ 배송 하루 빠르다        1  \n",
       "23139                                          시원 편하다 좋다        1  \n",
       "\n",
       "[23056 rows x 5 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:/Users/slugg/Documents/GitHub/three_idiot/data/전처리_예측/review_패션_유아동패션.csv', encoding='utf-8', index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzed_dict = al.analyze_all_reviews_with_dataframe(data) # star_count는 1점 -> 5점 순으로 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'total_reviews': 3,\n",
       "             'total_positive_reviews': 2,\n",
       "             'total_negative_reviews': 1,\n",
       "             'top_5_pos_keywords': [('귀엽다', 2),\n",
       "              ('크다', 1),\n",
       "              ('이쁘다', 1),\n",
       "              ('사이즈', 1),\n",
       "              ('색', 1)],\n",
       "             'top_5_neg_keywords': [('색', 1), ('빨래', 1)],\n",
       "             'star_count': {2: 1, 5: 2}})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzed_dict['1230133678']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_string = json.dumps(analyzed_dict, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/slugg/Documents/GitHub/three_idiot/data/output/output.json', 'w', encoding='utf-8') as jsfile:\n",
    "    jsfile.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
